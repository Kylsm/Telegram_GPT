import os
import openai
from dotenv import load_dotenv
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, ContextTypes, filters

load_dotenv()

openai.api_key = os.getenv("OPENAI_API_KEY")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("Ù‡Ù„Ø§! Ø£Ø±Ø³Ù„ Ù„ÙŠ Ø£ÙŠ Ø´ÙŠØ¡ØŒ ÙˆØ£Ù†Ø§ Ø¨Ø±Ø¯ Ø¹Ù„ÙŠÙƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT ğŸ¤–")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_message = update.message.text
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": user_message}]
        )
        bot_reply = response['choices'][0]['message']['content']
    except Exception as e:
        bot_reply = f"ØµØ§Ø± Ø®Ø·Ø£: {e}"
    await update.message.reply_text(bot_reply)

if __name__ == "__main__":
    app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & (~filters.COMMAND), handle_message))

    # ØªÙØ¹ÙŠÙ„ webhook Ø¹Ù„Ù‰ Ø¨ÙˆØ±Øª 10000 Ø¹Ø´Ø§Ù† ÙŠØªÙˆØ§ÙÙ‚ Ù…Ø¹ Render
    app.run_webhook(
        listen="0.0.0.0",
        port=int(os.environ.get("PORT", 10000)),
        webhook_url=f"https://{os.environ.get('RENDER_EXTERNAL_HOSTNAME')}/"
    )
